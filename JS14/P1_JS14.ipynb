{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Langkah 1 - Import Library"
      ],
      "metadata": {
        "id": "tmLHVob-Qz4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "oKettsxARTA7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaLhBoOoh7wj",
        "outputId": "c3a86349-bc8d-46c7-c66c-72a4afab5dec"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/ML/dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozx0kYIih3Sr",
        "outputId": "005c54e0-bcbf-42fa-bf21-35e6e3cbd059"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "single_prediction  test_set  training_set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Langkah 2 - Pra Pengolahan Data"
      ],
      "metadata": {
        "id": "LzlLWiFnQ2TM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Langkah 2.1. Pra Pengolahan Data Training"
      ],
      "metadata": {
        "id": "zIOD8foyQ38B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/ML/dataset/training_set',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGkh1yGAYBtK",
        "outputId": "41b93edc-a6f3-4cc8-8d48-cc5341d41edb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Langkah 2.2. Pra Pengolahan Data Testing"
      ],
      "metadata": {
        "id": "3m4Gw24lQ9X5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/ML/dataset/test_set',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')"
      ],
      "metadata": {
        "id": "HkhWxxCnRu7P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea6c5a87-013a-4c42-de43-93cd07125ace"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/ML/dataset/training_set',\n",
        "    target_size = (64, 64),\n",
        "    batch_size = 32,\n",
        "    class_mode = 'binary'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTtmsWDojXm6",
        "outputId": "1815e31f-dca1-463f-df66-c3f36800e4ce"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/ML/dataset/test_set',\n",
        "    target_size = (64, 64),\n",
        "    batch_size = 32,\n",
        "    class_mode = 'binary'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOjLcOGhjZiv",
        "outputId": "4e12b5ff-21f1-4397-a51d-e2515e0b22bf"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Langkah 3 - Pembuatan Model CNN"
      ],
      "metadata": {
        "id": "ahMh09p4Q-1y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Langkah 3.1.  - Inisiasi Model CNN"
      ],
      "metadata": {
        "id": "yYwkhM43RAKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "DzwfHUo4ieRR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Langkah 3.2. - Pembuatan Layer Konvolusi 1"
      ],
      "metadata": {
        "id": "GctBkUzrRBc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzImUe9hifsT",
        "outputId": "acc088d2-77e8-4192-bcd0-7970ece52e1a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Langkah 3.3 - Pembuatan Layer Pooling 1"
      ],
      "metadata": {
        "id": "YTV54_bXRElN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "amY86s7JiiVt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Langkah 3.4 - Pembuatan Layer Konvolusi 2 dan Pooling 2"
      ],
      "metadata": {
        "id": "0Bm6o_ULRGPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "VMtETs2Lij3B"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Langkah 3.5 - Flattening"
      ],
      "metadata": {
        "id": "ccx8wK-sRIfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "XkQNC_2YilYl"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Langkah 3.6 - Fully Connected Layer 1 (Input)"
      ],
      "metadata": {
        "id": "Q4pPauKWRJic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
      ],
      "metadata": {
        "id": "hYc97KvhinEF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Langkah 3.7 - Fully Connected Layer 2 (Output)"
      ],
      "metadata": {
        "id": "6XZabmnbRK_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "_a_gsR_Piocy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Langkah 3.8 - Compile Model CNN"
      ],
      "metadata": {
        "id": "_y-yGSQCRMKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "4MkqoCIUipln"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Langkah 4 - Fit CNN"
      ],
      "metadata": {
        "id": "t5phpWcuRNrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWqwN5Unirg9",
        "outputId": "c7707fb4-bff1-4c2e-a3e2-bbf1b799fa6b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1991s\u001b[0m 8s/step - accuracy: 0.5467 - loss: 0.6946 - val_accuracy: 0.5455 - val_loss: 0.7957\n",
            "Epoch 2/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 186ms/step - accuracy: 0.6397 - loss: 0.6362 - val_accuracy: 0.6915 - val_loss: 0.6054\n",
            "Epoch 3/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 188ms/step - accuracy: 0.6998 - loss: 0.5933 - val_accuracy: 0.7260 - val_loss: 0.5472\n",
            "Epoch 4/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 183ms/step - accuracy: 0.7139 - loss: 0.5598 - val_accuracy: 0.7385 - val_loss: 0.5230\n",
            "Epoch 5/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 187ms/step - accuracy: 0.7299 - loss: 0.5338 - val_accuracy: 0.7495 - val_loss: 0.5057\n",
            "Epoch 6/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 186ms/step - accuracy: 0.7343 - loss: 0.5134 - val_accuracy: 0.7495 - val_loss: 0.5038\n",
            "Epoch 7/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 185ms/step - accuracy: 0.7594 - loss: 0.4950 - val_accuracy: 0.7755 - val_loss: 0.4929\n",
            "Epoch 8/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 183ms/step - accuracy: 0.7737 - loss: 0.4728 - val_accuracy: 0.7695 - val_loss: 0.4729\n",
            "Epoch 9/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 186ms/step - accuracy: 0.7824 - loss: 0.4567 - val_accuracy: 0.7875 - val_loss: 0.4677\n",
            "Epoch 10/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 183ms/step - accuracy: 0.7901 - loss: 0.4447 - val_accuracy: 0.7590 - val_loss: 0.5014\n",
            "Epoch 11/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 185ms/step - accuracy: 0.7937 - loss: 0.4382 - val_accuracy: 0.7790 - val_loss: 0.4616\n",
            "Epoch 12/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 188ms/step - accuracy: 0.8043 - loss: 0.4175 - val_accuracy: 0.7770 - val_loss: 0.4690\n",
            "Epoch 13/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 186ms/step - accuracy: 0.8138 - loss: 0.3956 - val_accuracy: 0.7535 - val_loss: 0.5111\n",
            "Epoch 14/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 183ms/step - accuracy: 0.8266 - loss: 0.3951 - val_accuracy: 0.7775 - val_loss: 0.4871\n",
            "Epoch 15/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 185ms/step - accuracy: 0.8309 - loss: 0.3743 - val_accuracy: 0.7945 - val_loss: 0.4669\n",
            "Epoch 16/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 183ms/step - accuracy: 0.8337 - loss: 0.3638 - val_accuracy: 0.7850 - val_loss: 0.4780\n",
            "Epoch 17/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 188ms/step - accuracy: 0.8446 - loss: 0.3441 - val_accuracy: 0.7705 - val_loss: 0.5505\n",
            "Epoch 18/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 183ms/step - accuracy: 0.8529 - loss: 0.3291 - val_accuracy: 0.7790 - val_loss: 0.4942\n",
            "Epoch 19/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 190ms/step - accuracy: 0.8569 - loss: 0.3173 - val_accuracy: 0.7920 - val_loss: 0.4694\n",
            "Epoch 20/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 182ms/step - accuracy: 0.8617 - loss: 0.3010 - val_accuracy: 0.7820 - val_loss: 0.5119\n",
            "Epoch 21/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 183ms/step - accuracy: 0.8807 - loss: 0.2833 - val_accuracy: 0.7885 - val_loss: 0.5329\n",
            "Epoch 22/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 181ms/step - accuracy: 0.8804 - loss: 0.2786 - val_accuracy: 0.8040 - val_loss: 0.4890\n",
            "Epoch 23/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 184ms/step - accuracy: 0.8872 - loss: 0.2569 - val_accuracy: 0.8005 - val_loss: 0.5061\n",
            "Epoch 24/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 182ms/step - accuracy: 0.8932 - loss: 0.2585 - val_accuracy: 0.7855 - val_loss: 0.5501\n",
            "Epoch 25/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 184ms/step - accuracy: 0.8984 - loss: 0.2491 - val_accuracy: 0.7840 - val_loss: 0.5955\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c98d4f80770>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Langkah 5 - Prediksi dengan 1 Citra"
      ],
      "metadata": {
        "id": "hWdQ3AmDRO09"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "CT_wda8VQbmC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7db3af77-f802-41f0-dc4c-6bd6cb209c4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('/content/drive/MyDrive/ML/dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = cnn.predict(test_image)\n",
        "training_set.class_indices\n",
        "if result[0][0] == 1:\n",
        "  prediction = 'dog'\n",
        "else:\n",
        "  prediction = 'cat'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Hasil prediksi model (angka):\", result)\n",
        "print(\"Label yang terbaca:\", prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJ8bLeuLv4FS",
        "outputId": "a7f0c3ec-8459-43d4-ec18-47231cc2806a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hasil prediksi model (angka): [[1.]]\n",
            "Label yang terbaca: dog\n"
          ]
        }
      ]
    }
  ]
}