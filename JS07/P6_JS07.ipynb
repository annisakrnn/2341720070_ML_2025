{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjhoBEYCOV0m"
      },
      "source": [
        "# Praktikum 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiRIGtiNk_Vg",
        "outputId": "bff47314-1bf7-41ae-830f-0c264a7ffe30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N__FACOe4ks",
        "outputId": "547885f4-0372-463d-b177-04fcec9cfa93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Downloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.6/23.6 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.13.0\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSGqDtNie8W5",
        "outputId": "a834b11b-cb78-41b7-d3ff-8f757e737eb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting annoy\n",
            "  Downloading annoy-1.17.3.tar.gz (647 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/647.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m645.1/647.5 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.5/647.5 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting hnswlib\n",
            "  Downloading hnswlib-0.8.0.tar.gz (36 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from hnswlib) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Building wheels for collected packages: annoy, hnswlib\n",
            "  Building wheel for annoy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for annoy: filename=annoy-1.17.3-cp312-cp312-linux_x86_64.whl size=551810 sha256=e8247042a7c0b2a671047e45e2c290166d68b1c93f650cb312b4b0e76304ca86\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/b9/53/a3b2d1fe1743abadddec6aa541294b24fdbc39d7800bc57311\n",
            "  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hnswlib: filename=hnswlib-0.8.0-cp312-cp312-linux_x86_64.whl size=2528142 sha256=e52a881c6785afbe988650801954bd5efb608c66f17add883823f3a0b5c45449\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/39/b3/cbd7f9cbb76501d2d5fbc84956e70d0b94e788aac87bda465e\n",
            "Successfully built annoy hnswlib\n",
            "Installing collected packages: annoy, hnswlib\n",
            "Successfully installed annoy-1.17.3 hnswlib-0.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install annoy hnswlib scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2XtU6NsfLFa",
        "outputId": "88904895-2221-4e3a-c44a-47cfa17da059"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hnswlib in /usr/local/lib/python3.12/dist-packages (0.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from hnswlib) (2.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install hnswlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xd9thtSXesqY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import faiss\n",
        "from annoy import AnnoyIndex\n",
        "import hnswlib\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "ALp6-_Bykbk2",
        "outputId": "0ab59c34-2893-4619-c6b2-f6ffcabada19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exact NN done in 5854.991 s\n",
            "Annoy done in 77.187 s\n",
            "HNSW done in 364.028 s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "add_ref_in_constructor.<locals>.replacement_init() got an unexpected keyword argument 'nlist'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2401931902.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mquantizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfaiss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndexFlatL2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0mindex_faiss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfaiss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndexIVFFlat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquantizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_scaled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfaiss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMETRIC_L2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0mindex_faiss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0mindex_faiss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: add_ref_in_constructor.<locals>.replacement_init() got an unexpected keyword argument 'nlist'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import faiss\n",
        "from annoy import AnnoyIndex\n",
        "import hnswlib\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# -------------------------------\n",
        "# Load dataset\n",
        "# -------------------------------\n",
        "df = pd.read_csv('/content/drive/MyDrive/ML/spotify_song.csv')  # ganti path sesuai lokasi file\n",
        "features = ['danceability', 'energy', 'loudness', 'speechiness',\n",
        "            'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
        "X = df[features].values\n",
        "\n",
        "# Standarisasi fitur\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "k = 10  # jumlah nearest neighbors\n",
        "\n",
        "# -------------------------------\n",
        "# Exact Nearest Neighbor (brute-force)\n",
        "# -------------------------------\n",
        "start = time.time()\n",
        "nn = NearestNeighbors(n_neighbors=k, algorithm='brute', metric='euclidean')\n",
        "nn.fit(X_scaled)\n",
        "dist_exact, idx_exact = nn.kneighbors(X_scaled)\n",
        "time_exact = time.time() - start\n",
        "print(f\"Exact NN done in {time_exact:.3f} s\")\n",
        "\n",
        "# -------------------------------\n",
        "# Annoy\n",
        "# -------------------------------\n",
        "start = time.time()\n",
        "f = X_scaled.shape[1]\n",
        "index_annoy = AnnoyIndex(f, 'euclidean')\n",
        "for i, v in enumerate(X_scaled):\n",
        "    index_annoy.add_item(i, v)\n",
        "index_annoy.build(10)\n",
        "idx_annoy = [index_annoy.get_nns_by_vector(v, k) for v in X_scaled]\n",
        "time_annoy = time.time() - start\n",
        "print(f\"Annoy done in {time_annoy:.3f} s\")\n",
        "\n",
        "# -------------------------------\n",
        "# HNSW\n",
        "# -------------------------------\n",
        "start = time.time()\n",
        "p_hnsw = hnswlib.Index(space='l2', dim=X_scaled.shape[1])\n",
        "p_hnsw.init_index(max_elements=X_scaled.shape[0], ef_construction=200, M=16)\n",
        "p_hnsw.add_items(X_scaled)\n",
        "p_hnsw.set_ef(200)\n",
        "idx_hnsw, dist_hnsw = p_hnsw.knn_query(X_scaled, k=k)\n",
        "time_hnsw = time.time() - start\n",
        "print(f\"HNSW done in {time_hnsw:.3f} s\")\n",
        "\n",
        "# -------------------------------\n",
        "# FAISS IVF\n",
        "# -------------------------------\n",
        "start = time.time()\n",
        "quantizer = faiss.IndexFlatL2(X_scaled.shape[1])\n",
        "index_faiss = faiss.IndexIVFFlat(quantizer, X_scaled.shape[1], nlist=100, metric=faiss.METRIC_L2)\n",
        "index_faiss.train(X_scaled)\n",
        "index_faiss.add(X_scaled)\n",
        "index_faiss.nprobe = 10\n",
        "dist_faiss, idx_faiss = index_faiss.search(X_scaled, k)\n",
        "time_faiss = time.time() - start\n",
        "print(f\"FAISS IVF done in {time_faiss:.3f} s\")\n",
        "\n",
        "# -------------------------------\n",
        "# Contoh tampilkan top-5 neighbors dari item pertama\n",
        "# -------------------------------\n",
        "print(\"\\nTop-5 neighbors for first song:\")\n",
        "print(f\"Exact NN: {idx_exact[0][:5]}\")\n",
        "print(f\"Annoy:    {idx_annoy[0][:5]}\")\n",
        "print(f\"HNSW:     {idx_hnsw[0][:5]}\")\n",
        "print(f\"FAISS:    {idx_faiss[0][:5]}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}